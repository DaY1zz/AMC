{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bbe639f0c32c03",
   "metadata": {},
   "source": [
    "## 读取负载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a84725647514ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71616, 39388)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import polars as pl\n",
    "import sys\n",
    "sys.path.append('/home/dell/xyf/azurefunctions-dataset2019/analysis')\n",
    "\n",
    "\n",
    "\n",
    "file_name = \"/home/dell/xyf/azure-data/invocations_per_function_md.anon.d\"\n",
    "train_file_names, test_file_names = [file_name+\"%02d.csv\" % (i) for i in range(1, 13)], [file_name+\"13.csv\", file_name+\"14.csv\"]\n",
    "\n",
    "train_func_arrcount = {}    #函数负载数据\n",
    "train_func_owner_app = {}   \n",
    "train_owner_func = defaultdict(set)\n",
    "train_app_func = defaultdict(set)\n",
    "\n",
    "func_trigger = defaultdict(set)\n",
    "\n",
    "for i, file in enumerate(train_file_names):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        func = row[\"HashFunction\"]\n",
    "        train_func_owner_app[func] = row[\"HashOwner\"]+'\\t'+row[\"HashApp\"]\n",
    "        train_owner_func[row[\"HashOwner\"]].add(func)\n",
    "        train_app_func[row[\"HashApp\"]].add(func)\n",
    "        func_trigger[func].add(row[\"Trigger\"])\n",
    "        \n",
    "        if func not in train_func_arrcount:\n",
    "            train_func_arrcount[func] = [0]*12*1440     # 空缺补0\n",
    "        train_func_arrcount[func][i*1440: (i+1)*1440] = list(row[4:].values)\n",
    "    del df\n",
    "\n",
    "test_func_arrcount = {}\n",
    "test_func_owner_app = {}\n",
    "test_owner_func = defaultdict(set)\n",
    "test_app_func = defaultdict(set)\n",
    "\n",
    "for i, file in enumerate(test_file_names):\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        func = row[\"HashFunction\"]\n",
    "        test_func_owner_app[func] = row[\"HashOwner\"]+'\\t'+row[\"HashApp\"]\n",
    "        test_owner_func[row[\"HashOwner\"]].add(func)\n",
    "        test_app_func[row[\"HashApp\"]].add(func)\n",
    "        func_trigger[func].add(row[\"Trigger\"])\n",
    "        \n",
    "        if func not in test_func_arrcount:\n",
    "            test_func_arrcount[func] = [0]*2*1440       # 空缺补0\n",
    "        test_func_arrcount[func][i*1440: (i+1)*1440] = list(row[4:].values)\n",
    "    del df\n",
    "    \n",
    "train_NUM, test_NUM = len(train_func_arrcount), len(test_func_arrcount)\n",
    "train_NUM, test_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63235b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class func_state:\n",
    "    def __init__(self, _type = 0, forget = 0):\n",
    "        self.type = _type\n",
    "        self.forget = forget\n",
    "        \n",
    "        self.state = False # loaded or not\n",
    "        self.load_time = None \n",
    "        self.wait_time = None \n",
    "        self.last_call = None\n",
    "        self.pre_call_start = None # start of the last calling series\n",
    "        \n",
    "        self.idle_info = {} # \"mode\"：WT mode、 \"mode_count\": mode 出现次数\n",
    "        self.invok_info = {}\n",
    "        self.lasting_info = {}  #\n",
    "\n",
    "        self.pred_interval = [] # 预测值\n",
    "        self.pred_value = []\n",
    "        self.next_invok_start = []\n",
    "        \n",
    "        self.adp_wait = []\n",
    "    \n",
    "    def load(self, load_time):\n",
    "        self.state = True\n",
    "        self.load_time = load_time\n",
    "    \n",
    "    def cal_lasting(self, cur_time):\n",
    "        if not self.state:\n",
    "            return 0\n",
    "        return cur_time - self.load_time + 1\n",
    "    \n",
    "    def unload(self):\n",
    "        self.state = False\n",
    "        self.load_time = None\n",
    "    \n",
    "    def cal_wait(self):\n",
    "        if self.wait_time is None:\n",
    "            self.wait_time = 0\n",
    "        self.wait_time += 1\n",
    "    \n",
    "    def reset(self, pred=False):\n",
    "        self.unload()\n",
    "        self.wait_time = None \n",
    "        self.last_call = None\n",
    "        self.pre_call_start = None\n",
    "        \n",
    "        self.adp_wait = []\n",
    "        \n",
    "        if pred:\n",
    "            self.next_invok_start = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de50b807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71616\n",
      "72359 72359 39388 743\n"
     ]
    }
   ],
   "source": [
    "from common import *\n",
    "func_class = {}\n",
    "with open(\"/home/dell/xyf/azurefunctions-dataset2019/mid-data/train_info_assigned.txt\") as rf:    # 所有函数的负载数据 hashID  forget  loadarray\n",
    "    for line in rf:\n",
    "        func, type, forget = line.strip().split('\\t')\n",
    "        func_class[func] = func_state(_type=int(type), forget=int(forget))\n",
    "print(len(func_class))\n",
    "\n",
    "\n",
    "# 加载测试集函数\n",
    "func_lst, func_corr_lst = set(), set()\n",
    "num_unseen_func = 0\n",
    "for func in func_class:\n",
    "    if func_class[func].type == CORR:\n",
    "        func_corr_lst.add(func)\n",
    "    else:\n",
    "        func_lst.add(func)\n",
    "\n",
    "for func in test_func_arrcount:\n",
    "    if func in func_class: \n",
    "        continue\n",
    "    num_unseen_func += 1\n",
    "    func_lst.add(func)      # Unseen 函数 训练集中未出现的函数   \n",
    "    func_class[func] = func_state() \n",
    "    \n",
    "func_lst, func_corr_lst = list(func_lst), list(func_corr_lst)\n",
    "print(len(func_class), len(func_lst)+len(func_corr_lst), len(test_func_arrcount), num_unseen_func)\n",
    "\n",
    "# 筛选出可预测函数并根据训练集进行初步预测\n",
    "PE_THRESHOLD = 0.2\n",
    "\n",
    "CV_WT_UPPER_THRESHOLD = 5\n",
    "CV_WT_LOWER_THRESHOLD = 2\n",
    "\n",
    "LOCAL_WINDOW = 60*48\n",
    "PREDICT_WINDOW = 60\n",
    "\n",
    "PID_TARGET = 0.15   #冷启动率\n",
    "T_ALPHA = 0.2       #浮动参数\n",
    "BETA = 0.1          #实例参数\n",
    "\n",
    "HISTORY_TIMEOUT = 12*60     # 12小时  \n",
    "HISTORY_LENGTH = 6          # 6条调用记录\n",
    "IAT_MIN = 1\n",
    "IAT_QUANTILE = 0.8     #IAT置信分位数\n",
    "\n",
    "df = pl.read_csv(\"/home/dell/xyf/AMC/func_info.csv\")\n",
    "df = df.filter(pl.col('Type') != 2)   #过滤regular\n",
    "\n",
    "pe_df = df.filter(pl.col('PE') > PE_THRESHOLD)  #   PE > 0.2\n",
    "cv_WT_df = df.filter((pl.col('CV_WT') > CV_WT_LOWER_THRESHOLD))\\\n",
    "        .filter((pl.col('CV_WT') < CV_WT_UPPER_THRESHOLD))\\\n",
    "        .filter(~pl.col('CV_WT').is_nan())\\\n",
    "        .filter(pl.col('PE')> 0.1)\\\n",
    "                                                #  2 < CV_WT < 5 && PE > 0.1\n",
    "df_union = pl.concat([pe_df, cv_WT_df]).unique()    \n",
    "predictable_func_ids = df_union.select('Function').to_numpy().flatten().tolist()\n",
    "predictable_func_ids = set(predictable_func_ids)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c20542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11834\n",
      "72359\n",
      "39388\n",
      "9806\n"
     ]
    }
   ],
   "source": [
    "print(len(predictable_func_ids))\n",
    "\n",
    "all_func = set(func_lst+func_corr_lst)\n",
    "print(len(all_func))\n",
    "test_func = set(test_func_arrcount.keys())\n",
    "print(len(test_func))\n",
    "union_pred_test = predictable_func_ids  & test_func\n",
    "\n",
    "print(len(union_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307fdc5b",
   "metadata": {},
   "source": [
    "## 输出指标数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f3479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dell/xyf/azurefunctions-dataset2019/analysis')\n",
    "from analysis.data import *\n",
    "from analysis.plot import *\n",
    "\n",
    "df_load = pl.read_csv(PROCESSED_DIR+\"func_load_all_12days.csv\")\n",
    "\n",
    "# many_load_plot(df_load, df_load.columns[1:6],\".\",df_load.columns[1:6],COLOR_NAME,\"test_head.png\")\n",
    "# many_load_plot(df_load, df_load.columns[-5:],\".\",df_load.columns[-5:],COLOR_NAME,\"test_end.png\")\n",
    "\n",
    "cv_result = get_CV(df_load.drop('time'))\n",
    "print(len(cv_result))\n",
    "entropy_result = get_entropy(df_load.drop('time'))\n",
    "print(len(entropy_result))\n",
    "periodicity_result = get_periodicity(df_load.drop('time'))\n",
    "print(len(periodicity_result))\n",
    "\n",
    "result = [(id, cv, pe, period, strength) for (id, cv), (_, pe), (_, period, strength) in zip(cv_result, entropy_result, periodicity_result)]\n",
    "result_df = pl.DataFrame(result, schema=['Function', 'CV', 'PE', 'Period', 'Period_Strength'])\n",
    "print(result_df.count())\n",
    "\n",
    "median_reqs = get_median_reqs_per_day(df_load.drop('time'))\n",
    "median_reqs = median_reqs.with_columns(pl.col(\"Function\").cast(pl.String))\n",
    "\n",
    "\n",
    "result_df = pl.concat([result_df, median_reqs], how='align')\n",
    "# result_df.write_csv(PROCESSED_12DAYS_DIR+\"metric.csv\")\n",
    "print(result_df.count())\n",
    "plot_psd_data(result_df, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790e562",
   "metadata": {},
   "source": [
    "## 读取指标数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROCESSED_12DAYS_DIR = \"/home/dell/xyf/azurefunctions-dataset2019/processed/12days/\"\n",
    "DATASET_LENGTH = 12\n",
    "valid_split_DAY = 9\n",
    "label_lst = ['Unknown','Warm', 'Regular', \"Appro-regular\", \"Dense\", \"Successive\", \"Plused\", \"Possible\", \"Corr\"]\n",
    "CV_UPPER_THRESHOLD = 5\n",
    "CV_LOWER_THRESHOLD = 0.1\n",
    "PE_THRESHOLD = 0.2\n",
    "PERIOD_STRENGTH_THRESHOLD = 0.5\n",
    "\n",
    "func_class = {}\n",
    "with open(\"./mid-data/train_info_assigned.txt\") as rf:    # 所有函数的负载数据 hashID  forget  loadarray\n",
    "    for line in rf:\n",
    "        func, type, forget = line.strip().split('\\t')\n",
    "        func_class[func] = func_state(_type=type, forget=forget)\n",
    "\n",
    "metric_df = pl.read_csv(PROCESSED_12DAYS_DIR+\"metric.csv\")\n",
    "\n",
    "type_list = []\n",
    "for func, state in func_class.items():\n",
    "    type_list.append((func, state.type))\n",
    "    \n",
    "type_df = pl.DataFrame(type_list, schema=['Function', 'Type'])\n",
    "df = metric_df.join(type_df, on='Function')\n",
    "\n",
    "\n",
    "df = df.filter(pl.col('Type') != '2')\n",
    "cv_df = df.filter(pl.col('CV') < CV_UPPER_THRESHOLD).filter(pl.col('CV') > CV_LOWER_THRESHOLD)\n",
    "pe_df = df.filter(pl.col('PE') > PE_THRESHOLD)\n",
    "period_df = (df.filter((pl.col('Period_Strength') > PERIOD_STRENGTH_THRESHOLD))\n",
    "             .filter(~pl.col('Period').is_infinite()).filter(pl.col('CV') > CV_LOWER_THRESHOLD))\n",
    "\n",
    "print(period_df)\n",
    "filtered_df = period_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb29fecea38b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_ids = filtered_df.select('Function').to_numpy().flatten()\n",
    "print(len(func_ids))\n",
    "\n",
    "for func in func_ids:\n",
    "    arr = train_func_arrcount[func]\n",
    "    print(arr[:50])\n",
    "    plt.figure(figsize=(16,8))\n",
    "    x1 = [i for i in range(1, len(arr) + 1)]\n",
    "    \n",
    "    plt.plot(x1, arr, color=\"blue\")\n",
    "    func_info = filtered_df.filter(pl.col('Function') == func).to_dict(as_series=False)\n",
    "    print(func)\n",
    "    print(label_lst[int(func_info['Type'][0])])\n",
    "    print(func_info['CV'][0])\n",
    "    print(func_info['PE'][0])\n",
    "    print(func_info['Period'][0])\n",
    "    print(func_info['Period_Strength'][0])\n",
    "    # 设置坐标轴刻度标签的大小\n",
    "    plt.tick_params(axis='x', direction='out',\n",
    "                   labelsize=12, length=3.6)\n",
    "    plt.tick_params(axis='y', direction='out',\n",
    "                   labelsize=12, length=3.6)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a593585dc1c26cf4",
   "metadata": {},
   "source": [
    "## 轻量级预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20515c532701698f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from LazyProphet import LazyProphet as lp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "LOCAL_WINDOW = 60*24\n",
    "PREDICT_WINDOW = 60*3\n",
    "\n",
    "# LighGBM 的参数\n",
    "boosting_params = {\n",
    "                    \"objective\": \"regression\",\n",
    "                    \"metric\": \"mape\",\n",
    "                    \"verbosity\": -1,\n",
    "                    \"boosting_type\": \"gbdt\",\n",
    "                    \"seed\": 42,\n",
    "                    \"learning_rate\": 0.1,\n",
    "                    \"min_child_samples\": 4,\n",
    "                    \"num_leaves\": 128,\n",
    "                    \"num_iterations\": 100\n",
    "                                }\n",
    "\n",
    "pred_func_account = {}\n",
    "func_ids = filtered_df.select('Function').to_numpy().flatten()\n",
    "c = 0\n",
    "\n",
    "def sliding_window_prediction(model, train_data, valid_data, local_window, predict_window):\n",
    "    valid_size = len(valid_data)\n",
    "    predictions = []\n",
    "    extended_train_data = np.copy(train_data)\n",
    "    \n",
    "    for start in range(0, valid_size, predict_window):\n",
    "        # Update training data by including part of the validation data\n",
    "        window_data = np.concatenate((extended_train_data, valid_data[:start]))\n",
    "        \n",
    "        if len(window_data) > local_window:\n",
    "            window_data = window_data[-local_window:]\n",
    "        \n",
    "        model.fit(window_data)\n",
    "        pred = model.predict(predict_window).flatten()\n",
    "        pred = list(map(lambda x: round(x) if x > 0 else 0, pred))\n",
    "        predictions.extend(pred)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "with tqdm(total=len(func_ids)) as pbar:\n",
    "    for func in func_ids:\n",
    "        c += 1\n",
    "        lp_model = lp.LazyProphet(scale=True,\n",
    "                          seasonal_period=[24, 168],\n",
    "                          n_basis=8,\n",
    "                          fourier_order=10,\n",
    "                          ar=list(range(1, 97)),\n",
    "                          decay=.99,\n",
    "                          linear_trend=None,\n",
    "                          decay_average=False,\n",
    "                          boosting_params=boosting_params\n",
    "                          )\n",
    "        arr = train_func_arrcount[func]\n",
    "        train_arr, valid_arr = arr[:1440 * valid_split_DAY], arr[1440 * valid_split_DAY:]\n",
    "        pred_result = sliding_window_prediction(lp_model, train_arr, valid_arr, LOCAL_WINDOW, PREDICT_WINDOW)\n",
    "        # fitted = lp_model.fit(train_arr)\n",
    "        # pred_result = lp_model.predict(len(valid_arr)).flatten()\n",
    "        # pred_result = list(map(lambda x: round(x) if x > 0 else 0, pred_result))\n",
    "        pred_func_account[func] = pred_result\n",
    "\n",
    "        if c % 10 == 0:\n",
    "            pbar.update(10)\n",
    "\n",
    "with open('cv_func_pred_data.pkl', 'wb') as f:\n",
    "    pkl.dump(pred_func_account, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc986f52e34ec29d",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e3975dfc8038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import pickle as pkl\n",
    "\n",
    "def smape(A, F):\n",
    "    # SMAPE  对称绝对百分比误差\n",
    "    sMAPE = 1 / len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "    return f\"{sMAPE:.2%}\"\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    cal = [abs(i - j) for i, j in zip(y_true, y_pred)]\n",
    "    result = (sum(cal) / len(cal))\n",
    "    return round(result, 2)\n",
    "\n",
    "with open('period_func_pred_data.pkl','rb') as f:\n",
    "    pred_func_account = pkl.load(f)\n",
    "\n",
    "for func , _ in pred_func_account.items():\n",
    "    pred_result = np.array(pred_func_account[func],dtype=int)\n",
    "    arr = train_func_arrcount[func]\n",
    "    print(arr[:30])\n",
    "\n",
    "    train_arr = np.array(train_func_arrcount[func][:1440 * valid_split_DAY],dtype=int)\n",
    "    valid_arr = np.array(train_func_arrcount[func][1440 * valid_split_DAY:],dtype=int)\n",
    "    \n",
    "    # result_sMAPE =smape(valid_arr, pred_result)\n",
    "    result_MAE = mae(valid_arr, pred_result)\n",
    "    r_square = r2_score(valid_arr, pred_result)\n",
    "\n",
    "    # print(\"sMAPE: \", result_sMAPE)\n",
    "    func_info = filtered_df.filter(pl.col('Function') == func).to_dict(as_series=False)\n",
    "    print(func)\n",
    "    print(label_lst[int(func_info['Type'][0])])\n",
    "    print(\"CV:  \", func_info['CV'][0])\n",
    "    print(\"PE:  \", func_info['PE'][0])\n",
    "    print(\"Period:  \", func_info['Period'][0])\n",
    "    print(\"Period_Strength: \", func_info['Period_Strength'][0])\n",
    "    print(\"MAE: \", result_MAE)\n",
    "    print(\"R2 Score: {:.2f}\".format(r_square))\n",
    "\n",
    "    plt.rcParams['axes.unicode_minus'] = False        # 显示负号\n",
    "    \n",
    "    plt.figure(figsize=(16,8))\n",
    "    x1 = [i for i in range(1, len(arr) + 1)]\n",
    "    x2 = [i for i in range(len(train_arr), len(train_arr) + len(valid_arr))]\n",
    "    \n",
    "    plt.plot(x1, arr, color=\"blue\")\n",
    "    plt.plot(x2, pred_result, color=\"red\", label=\"Actual\")\n",
    "    plt.axvline(len(train_arr), color=\"#00FF3A\", label=\"Forecast\")\n",
    "    \n",
    "    # 设置坐标轴刻度标签的大小\n",
    "    plt.tick_params(axis='x', direction='out',\n",
    "                   labelsize=12, length=3.6)\n",
    "    plt.tick_params(axis='y', direction='out',\n",
    "                   labelsize=12, length=3.6)\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
